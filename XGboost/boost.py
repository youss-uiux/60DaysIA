import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from xgboost import XGBClassifier, plot_importance
from sklearn.metrics import (accuracy_score, confusion_matrix, 
                            classification_report, roc_curve, auc, RocCurveDisplay)
from sklearn.preprocessing import StandardScaler

# 1. Chargement du fichier local
# Objectif : Charger le dataset Pima Indians Diabetes depuis un fichier CSV local.
data = pd.read_csv("diabetes.csv")

# V√©rification des colonnes pour s'assurer que le dataset est correctement charg√©.
print("Colonnes disponibles :", data.columns.tolist())

# 2. Pr√©traitement des donn√©es
# Objectif : Nettoyer les donn√©es en rempla√ßant les valeurs aberrantes (0) par NaN, puis imputer par la m√©diane.
def clean_data(df):
    # Remplacement des 0 par NaN pour les caract√©ristiques m√©dicales (0 est biologiquement impossible).
    medical_features = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']
    df[medical_features] = df[medical_features].replace(0, np.nan)
    
    # Imputation par la m√©diane pour g√©rer les valeurs manquantes.
    df.fillna(df.median(), inplace=True)
    
    return df

data = clean_data(data)

# 3. Visualisations avant mod√©lisation
# Objectif : Explorer les donn√©es avec diff√©rents graphiques pour mieux comprendre les relations entre variables.
# Chaque graphique est dans une fen√™tre s√©par√©e et sauvegard√© localement.

# Distribution du Glucose par statut diab√©tique
plt.figure(figsize=(8, 6))
sns.histplot(data=data, x='Glucose', hue='Outcome', bins=30, kde=True)
plt.title('Distribution du Glucose par statut diab√©tique')
plt.savefig("glucose_distribution.png")
plt.show()

# Relation √Çge/IMC
plt.figure(figsize=(8, 6))
sns.scatterplot(data=data, x='Age', y='BMI', hue='Outcome', palette='viridis')
plt.title('Relation √Çge/IMC')
plt.savefig("age_bmi_relation.png")
plt.show()

# Heatmap de corr√©lation
plt.figure(figsize=(8, 6))
corr_matrix = data.corr()
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)
plt.title('Matrice de corr√©lation')
plt.savefig("correlation_matrix.png")
plt.show()

# Distribution de l'insuline
plt.figure(figsize=(8, 6))
sns.boxplot(x='Outcome', y='Insulin', data=data)
plt.title('Niveau d\'insuline par statut diab√©tique')
plt.savefig("insulin_distribution.png")
plt.show()

# Relation grossesses/diab√®te
plt.figure(figsize=(8, 6))
sns.countplot(data=data, x='Pregnancies', hue='Outcome')
plt.title('Nombre de grossesses et diab√®te')
plt.savefig("pregnancies_diabetes.png")
plt.show()

# 4. Pr√©paration des donn√©es
# Objectif : S√©parer les features (X) et la cible (y), normaliser les donn√©es, et diviser en ensembles d'entra√Ænement/test.
X = data.drop('Outcome', axis=1)
y = data['Outcome']

# Normalisation des features avec StandardScaler pour que toutes les variables aient une √©chelle comparable.
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Division en ensembles d'entra√Ænement (70%) et de test (30%).
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)

# 5. Mod√®le XGBoost optimis√©
# Objectif : Entra√Æner un mod√®le XGBoost avec des hyperparam√®tres optimis√©s pour la classification binaire.
params = {
    'learning_rate': 0.05,        # Taux d'apprentissage pour ajuster la contribution de chaque arbre.
    'n_estimators': 200,          # Nombre d'arbres dans le mod√®le.
    'max_depth': 4,               # Profondeur maximale des arbres pour √©viter le surajustement.
    'subsample': 0.9,             # Fraction des √©chantillons utilis√©s pour entra√Æner chaque arbre.
    'colsample_bytree': 0.7,      # Fraction des features utilis√©es pour chaque arbre.
    'gamma': 0.1,                 # R√©gularisation pour limiter la croissance des arbres.
    'eval_metric': 'logloss'      # M√©trique d'√©valuation (log loss pour la classification binaire).
}

model = XGBClassifier(**params)
model.fit(X_train, y_train)

# 6. √âvaluation
# Objectif : Faire des pr√©dictions et √©valuer le mod√®le avec des m√©triques comme le rapport de classification et la matrice de confusion.
y_pred = model.predict(X_test)
y_probs = model.predict_proba(X_test)[:, 1]

print("\nüîç Rapport de classification :")
print(classification_report(y_test, y_pred))

print("\nüìä Matrice de confusion :")
print(confusion_matrix(y_test, y_pred))

# 7. Visualisation des r√©sultats
# Objectif : G√©n√©rer des graphiques pour analyser la performance du mod√®le (importance des features et courbe ROC).
# Chaque graphique est dans une fen√™tre s√©par√©e et sauvegard√© localement.

# Importance des caract√©ristiques
plt.figure(figsize=(8, 6))
plot_importance(model, height=0.8)
plt.title('Importance des caract√©ristiques')
plt.savefig("feature_importance.png")
plt.show()

# Courbe ROC
plt.figure(figsize=(8, 6))
RocCurveDisplay.from_estimator(model, X_test, y_test)
plt.title('Courbe ROC')
plt.plot([0, 1], [0, 1], 'k--')
plt.savefig("roc_curve.png")
plt.show()

# Matrice de confusion (ajout√©e pour comparer les donn√©es r√©elles et pr√©dites, comme demand√©)
plt.figure(figsize=(8, 6))
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
            xticklabels=['Non diab√©tique', 'Diab√©tique'], 
            yticklabels=['Non diab√©tique', 'Diab√©tique'])
plt.title("Matrice de confusion : R√©elles vs Pr√©dites (Diab√®te)")
plt.xlabel("Pr√©dictions")
plt.ylabel("Valeurs r√©elles")
plt.savefig("confusion_matrix_diabetes.png")
plt.show()

# 8. Interpr√©tation avec SHAP (optionnel mais recommand√©)
# Objectif : Analyser l'impact des features sur les pr√©dictions avec SHAP (si install√©).
try:
    import shap
    explainer = shap.TreeExplainer(model)
    shap_values = explainer.shap_values(X_train)
    
    plt.figure(figsize=(10, 8))
    shap.summary_plot(shap_values, X_train, feature_names=data.columns[:-1])
    plt.title('Analyse SHAP - Impact des caract√©ristiques')
    plt.savefig("shap_summary.png")
    plt.show()
except ImportError:
    print("\n‚ö†Ô∏è Pour l'analyse SHAP, installez le package : pip install shap")

# 9. Pr√©diction pour un nouveau patient (exemple)
# Objectif : Faire une pr√©diction pour un patient fictif pour illustrer l'utilisation pratique du mod√®le.
new_patient = [[1, 150, 72, 35, 0, 33.6, 0.627, 50]]  # Exemple de donn√©es
scaled_patient = scaler.transform(new_patient)
prediction = model.predict(scaled_patient)
probability = model.predict_proba(scaled_patient)[0][1]

print(f"\nü©∫ R√©sultat pr√©dictif pour le nouveau patient :")
print(f"- Classe pr√©dite : {'Diab√©tique' if prediction[0] else 'Non diab√©tique'}")
print(f"- Probabilit√© de diab√®te : {probability*100:.1f}%")